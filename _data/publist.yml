- title: "How do Minimum-Norm Shallow Denoisers Look in Function Space?"
  image: dummy.png
  description:  " "
  authors: C. Zeno, G. Ongie, Y. Blumenfeld, N. Weinbergery, **D. Soudry**
  link:
    url: https://arxiv.org/abs/2311.06748
    display:  NeurIPS 2023 
  highlight: 0
  news1: 

- title: "DropCompute: simple and more robust distributed synchronous training via compute variance reduction"
  image: DropComputePaper.JPG
  description:  We study a typical scenario in which workers are straggling due to variability in compute time. We find an analytical relation between compute time properties and scalability limitations, caused by such straggling workers.
  authors: N. Giladi *, S. Gottlieb * , M. Shkolnik, A. Karnieli, R. Banner, E. Hoffer, K. Y. Levy, **D. Soudry**  
  link:
    url: https://arxiv.org/abs/2306.10598 
    display:  NeurIPS 2023 
  highlight: 1
  news1: 


- title: "Explore to Generalize in Zero-Shot RL"
  image: dummy.png
  description:  " "
  authors: E. Zisselman, I. Lavie, **D. Soudry**, A. Tamar 
  link:
    url: https://arxiv.org/abs/2306.03072
    display:  NeurIPS 2023 
  highlight: 0
  news1:


- title: "Gradient Descent Monotonically Decreases the Sharpness of Gradient Flow Solutions in Scalar Networks and Beyond"
  image: dummy.png
  description:  " "
  authors:  I. Kreisler *, M. Shpigel Nacson *, **D. Soudry**, Yair Carmon
  link:
    url: https://arxiv.org/abs/2305.13064
    display:  ICML 2023 
  highlight: 0
  news1: 

- title: "Continual Learning in Linear Classification on Separable Data"
  image: dummy.png
  description:  " "
  authors:  I. Evron, E. Moroshko, G. Buzaglo, M. Khriesh, B. Marjieh, N. Srebro, **D. Soudry**
  link:
    url: https://arxiv.org/abs/2306.03534
    display:  ICML 2023
  highlight: 0
  news1: 

- title: "Alias-Free Convnets: Fractional Shift Invariance via Polynomial Activations"
  image: AliasPaper.JPG
  description: We propose an extended anti-aliasing method that tackles both downsampling and non-linear layers, thus creating truly alias-free, shift-invariant CNNs.
  authors: H. Michaeli, T. Michaeli, **D. Soudry**
  link:
    url: https://arxiv.org/abs/2303.08085
    display: CVPR 2023 
  highlight: 1
  news1:   <a href="https://hmichaeli.github.io/alias_free_convnets/"> See more details about this paper </a>

- title: "The Implicit Bias of Minima Stability in Multivariate Shallow ReLU Networks"
  image: TheImplicitPaper.JPG
  description: We study the type of solutions to which stochastic gradient descent converges when used to train a single hidden-layer multivariate ReLU network with the quadratic loss. Our results are based on a dynamical stability analysis.
  authors: M. Shpigel Nacson, R. Mulayoff, G. Ongie, T. Michaeli, **D. Soudry**
  link:
    url: https://arxiv.org/abs/2306.17499
    display: ICLR 2023 
  highlight: 1

- title: "Optimal Fine-Grained N:M sparsity for Activations and Neural Gradients"
  image: dummy.png
  description:  " "
  authors: B. Chmiel, I. Hubara, R. Banner, **D. Soudry**
  link:
    url: https://arxiv.org/abs/2203.10991
    display:   ICLR 2023 ("notable top 25%" of accepted papers)
  highlight: 0
  news1: 

- title: "Accurate Neural Training with 4-bit Matrix Multiplications at Standard Formats"
  image: AccurateNeuralPaper.JPG
  description: Previous works separately showed that accurate 4-bit quantization of the neural gradients needs to (1) be unbiased and (2) have a log scale. However, no previous work aimed to combine both ideas, as we do in this work. Specifically, we examine the importance of having unbiased quantization in quantized neural network training, where to maintain it, and how to combine it with logarithmic. 
  authors: B. Chmiel, R. Banner, E. Hoffer, H. Ben Yaacov, **D. Soudry**
  link:
    url: https://openreview.net/forum?id=yTbNYYcopd
    display: ICLR 2023
  highlight: 1
  news1: 
  news2: 

- title: "The Role of Codeword-to-Class Assignments in Error Correcting Codes: An Empirical Study"
  image: dummy.png
  description:  " "
  authors: I. Evron * , O. Onn * , T. Weiss, H. Azeroual,**D. Soudry**
  link:
    url: hhttps://arxiv.org/pdf/2302.05334
    display:   AISTAT 2023 
  highlight: 0
  news1: 

- title: "How catastrophic can catastrophic forgetting be in linear regression?"
  image: HowCatastrophicPaper.JPG
  description: To better understand catastrophic forgetting, we study fitting an overparameterized linear model to a sequence of tasks with different input distributions. We analyze how much the model forgets the true labels of earlier tasks after training on subsequent tasks, obtaining exact expressions and bounds.
  authors:  I. Evron, E. Moroshko, R. Ward, N. Srebro, **D. Soudry**
  link:
    url: https://arxiv.org/abs/2205.09588
    display:  COLT 2022 
  highlight: 1
  news2:

- title: "Implicit Bias of the Step Size in Linear Diagonal Neural Networks"
  image: dummy.png
  description:  " "
  authors: M. Shpigel-Nacson, K. Ravichandran, N. Srebro,**D. Soudry**
  link:
    url: https://proceedings.mlr.press/v162/nacson22a/nacson22a.pdf
    display: ICML 2022
  highlight: 0
  news1: 

- title: "A Statistical Framework for Efficient Out of Distribution Detection in Deep Neural Networks"
  image: StatisicalFrameworkPaper.JPG
  description: We frame Out Of Distribution (OOD) detection in DNNs as a statistical hypothesis testing problem. Tests generated within our proposed framework combine evidence from the entire network.
  authors: M. Haroush, T. Frostig, R. Heller, **D. Soudry**
  link:
    url: https://openreview.net/forum?id=Oy9WeuZD51
    display:   ICLR 2022 (2022)
  highlight: 1
  news2: 

- title: "Regularization Guarantees Generalization in Bayesian Reinforcement Learning through Algorithmic Stability"
  image: dummy.png
  description:  " "
  authors:  A. Tamar, **D. Soudry**, E. Zisselman
  link:
    url: https://proceedings.mlr.press/v162/nacson22a/nacson22a.pdf
    display: AAAI 2022 (15% acceptance rate)
  highlight: 0
  news1: 

- title: "Accelerated Sparse Neural Training: A Provable and Efficient Method to Find N:M Transposable Masks"
  image: AcceleratedSparsePaper.JPG
  description:  In this work, we first suggest a new measure called mask-diversity which correlates with the expected accuracy of the different types of structural pruning.
  authors: I. Hubara, B. Chmiel, M. Island, R. Banner, S. Naor, **D. Soudry**
  link:
    url: https://arxiv.org/abs/2102.08124
    display:  NeurIPS 2021 (2021)
  highlight: 1
  news1: <a href="https://github.com/papers-submission/structured_transposable_masks"> See more details about this paper </a>

- title: "Physics-Aware Downsampling with Deep Learning for Scalable Flood Modeling"
  image: dummy.png
  description:  " "
  authors: N. Giladi, Z. Ben-Haim, S. Nevo, Y. Matias,**D. Soudry**
  link:
    url: https://arxiv.org/abs/2106.07218
    display:  NeurIPS 2021
  highlight: 0
  news1: 

- title: "The Implicit Bias of Minima Stability: A View from Function Space"
  image: dummy.png
  description:  " "
  authors: R. Mulayoff, T. Michaeli, **D. Soudry**
  link:
    url: https://openreview.net/forum?id=2STmSnZAEt2
    display:  NeurIPS 2021
  highlight: 0
  news1: 

- title:  "On the Implicit Bias of Initialization Shape: Beyond Infinitesimal Mirror Descent"
  image: dummy.png
  description:  " "
  authors: S. Azulay, E. Moroshko, M. Shpigel Nacson, B. Woodworth, N. Srebro, A. Globerson, **D. Soudry**
  link:
    url: https://arxiv.org/abs/2102.09769
    display:  ICML 2021, Long talk (3% acceptance rate).
  highlight: 0
  news1: 

- title: "Accurate Post Training Quantization With Small Calibration Sets"
  image: dummy.png
  description:  " "
  authors:  I. Hubara * , Y. Nahshan * , Y. Hanani*, R. Banner, **D. Soudry**
  link:
    url: https://arxiv.org/abs/2006.10518
    display:  ICML 2021
  highlight: 0
  news1: 

  
- title: "Neural gradients are near-lognormal: understanding sparse and quantized training"
  image: NeuralGradientPaper.JPG
  description: We find that the distribution of neural gradients is approximately lognormal. Considering this, we suggest two closed-form analytical methods to reduce the computational and memory burdens of neural gradients.
  authors: B. Chmiel * , L. Ben-Uri * , M. Shkolnik, E. Hoffer, R. Banner, **D. Soudry**  
  link:
    url: https://openreview.net/forum?id=EoFNy62JGd
    display:  ICLR 2021 (2021)
  highlight: 1
  news2:


- title: "Implicit Bias in Deep Linear Classification: Initialization Scale vs Training Accuracy"
  image: ImplicitBiasinDeepPaper.JPG
  description: We provide a detailed asymptotic study of gradient flow trajectories and their implicit optimization bias when minimizing the exponential loss over "diagonal linear networks". This is the simplest model displaying a transition between "kernel" and non-kernel ("rich" or "active") regimes.
  authors:  E. Moroshko, S. Gunasekar, B. Woodworth, J. D. Lee, N. Srebro, **D. Soudry**
  link:
    url: https://arxiv.org/abs/2007.06738
    display:  NeurIPS 2020, Spotlight (3% acceptance rate) (2020)
  highlight: 1
  news2: 

- title: "Beyond Signal Propagation: Is Feature Diversity Necessary in Deep Neural Network Initialization?"
  image: dummy.png
  description:  " "
  authors: Y. Blumenfeld, D. Gilboa, **D. Soudry**
  link:
    url: https://arxiv.org/abs/2007.01038
    display:  ICML 2020
  highlight: 0
  news1: 

- title: "Kernel and Rich Regimes in Overparametrized Models"
  image: dummy.png
  description:   " "
  authors: B. Woodworth, S. Gunasekar,  P. Savarese, E. Moroshko, I. Golan, J. Lee, **D. Soudry**, N. Srebro
  link:
    url: https://arxiv.org/abs/2002.09277
    display:  COLT 2020
  highlight: 0
  news1: 

- title: "The Knowledge Within: Methods for Data-Free Model Compression"
  image: TheKnowledgeWithinPaper.JPG
  authors:  M. Haroush, I. Hubara, E. Hoffer, **D. Soudry**
  description: Recently, an extensive amount of research has been focused on compressing and accelerating Deep Neural Networks (DNN). So far, high compression rate algorithms require part of the training dataset for a low precision calibration, or a fine-tuning process. However, this requirement is unacceptable when the data is unavailable or contains sensitive information, as in medical and biometric use-cases. We present three methods for generating synthetic samples from trained models.
  link:
    url: https://arxiv.org/abs/1912.01274
    display:   CVPR 2020 
  highlight: 1
  news2:


- title: "Augment Your Batch: Improving Generalization Through Instance Repetition"
  image: dummy.png
  description:  " "
  authors: E. Hoffer, T. Ben-Nun, N. Giladi, I. Hubara, T. Hoefler, **D. Soudry**
  link:
    url: https://arxiv.org/abs/1901.09335
    display:  CVPR 2020
  highlight: 0
  news1: 

- title: "At Stability's Edge: How to Adjust Hyperparameters to Preserve Minima Selection in Asynchronous Training of Neural Networks?"
  image: AtStabilityEdgePaper.JPG
  authors: N. Giladi *, M. Shpigel Nacson *, E. Hoffer, **D. Soudry** 
  description: We examine asynchronous training from the perspective of dynamical stability. We find that the degree of delay interacts with the learning rate, to change the set of minima accessible by an asynchronous stochastic gradient descent algorithm. We derive closed-form rules on how the learning rate could be changed, while keeping the accessible set the same.
  link:
    url: https://arxiv.org/abs/1909.12340
    display:  ICLR 2020 
  highlight: 1
  news2:


- title: "A Function Space View of Bounded Norm Infinite Width ReLU Nets: The Multivariate Case"
  image: dummy.png
  description:  " "
  authors: G. Ongie, R. Willett, **D. Soudry**, N. Srebro
  link:
    url: https://arxiv.org/pdf/1910.01635.pdf
    display:  ICLR 2020 
  highlight: 0
  news1: <a href="https://www.youtube.com/watch?v=WObxWBLAdsA"> video about this paper </a>
  
  
- title: "A Mean Field Theory of Quantized Deep Networks: The Quantization-Depth Trade-Off"
  image: MeanFieldPaper.JPG
  description: We apply mean-field techniques to networks with quantized activations in order to evaluate the degree to which quantization degrades signal propagation at initialization. We derive initialization schemes which maximize signal propagation in such networks and suggest why this is helpful for generalization.
  authors: Y. Blumenfeld, D. Gilboa, **D. Soudry**
  link:
    url: https://arxiv.org/abs/1906.00771
    display:  NeurIPS 2019
  highlight: 1
  news2:

- title: "Post-training 4-bit quantization of convolution networks for rapid-deployment"
  image: PostTrainingPaper.JPG
  description: This paper introduces the first practical 4-bit post training quantization approach.
  authors: R. Banner, Y. Nahshan, **D. Soudry**
  link:
    url: https://arxiv.org/abs/1810.05723
    display:   NeurIPS 2019 
  highlight: 1
  news1:  <a href = "https://github.com/submission2019/cnn-quantization"> See more details about this paper </a> 

- title: "Lexicographic and Depth-Sensitive Margins in Homogeneous and Non-Homogeneous Deep Models"
  image: dummy.png
  description:  " "
  authors: M. Shpigel Nacson, S. Gunasekar, J. Lee, N. Srebro, **D. Soudry**
  link:
    url: https://arxiv.org/pdf/1905.07325.pdf
    display:  ICML 2019 
  highlight: 0
  news1: 
 

- title: "How do infinite width bounded norm networks look in function space?"
  image: HowToInfinitePaper.JPG
  description: We consider the question of what functions can be captured by ReLU networks with an unbounded number of units (infinite width), but where the overall network Euclidean norm (sum of squares of all weights in the system, except for an unregularized bias term for each unit) is bounded.  
  authors: P. Savarese, I. Evron, **D. Soudry**, N. Srebro
  link:
    url: https://arxiv.org/abs/1902.05040
    display: COLT 2019 
  highlight: 1
  news2: 

- title: "Convergence of Gradient Descent on Separable Data"
  image: dummy.png
  description:  " "
  authors: M. Shpigel Nacson, J. Lee, S. Gunasekar, N. Srebro, **D. Soudry**
  link:
    url: https://arxiv.org/abs/1803.01905
    display:  AISTATS 2019, Oral Presentation (2.5% acceptance rate). 
  highlight: 0
  news1: 

- title: "Stochastic Gradient Descent on Separable Data: Exact Convergence with a Fixed Learning Rate"
  image: dummy.png
  description:  " "
  authors: M. Shpigel Nacson, N. Srebro, **D. Soudry**
  link:
    url: https://arxiv.org/abs/1806.01796v3
    display:  AISTATS 2019 
  highlight: 0
  news1: 

- title: "Norm matters: efficient and accurate normalization schemes in deep networks"
  image: dummy.png
  description:  " "
  authors: E. Hoffer * , R. Banner * , I. Golan * , **D. Soudry**
  link:
    url: https://proceedings.neurips.cc/paper_files/paper/2018/file/a0160709701140704575d499c997b6ca-Paper.pdf
    display:   NeurIPS 2018, Spotlight (3.5% acceptance rate)
  highlight: 0
  news1: 

- title: "Implicit Bias of Gradient Descent on Linear Convolutional Networks"
  image: dummy.png
  description:  " "
  authors: S. Gunasekar, J. D. Lee, **D. Soudry**, N. Srebro
  link:
    url:  https://arxiv.org/abs/1806.00468
    display:   NeurIPS 2018
  highlight: 0
  news1: 

  
- title: "Scalable Methods for 8-bit Training of Neural Networks"
  image: ScalableMethodPaper.JPG
  description: Our theoretical analysis suggests that most of the training process is robust to substantial precision reduction, and points to only a few specific operations that require higher precision. Armed with this knowledge, we quantize the model parameters, activations and layer gradients to 8-bit, leaving at a higher precision only the final step in the computation of the weight gradients. Additionally, as QNNs require batch-normalization to be trained at high precision, we introduce Range Batch-Normalization (BN) which has significantly higher tolerance to quantization noise and improved computational complexity.
  authors: R. Banner, I. Hubara, E. Hoffer, **D. Soudry**
  link:
    url: https://arxiv.org/abs/1805.11046
    display:  NeurIPS 2018
  highlight: 1
  news2:

- title: "Characterizing Implicit Bias in Terms of Optimization Geometry"
  image: dummy.png
  description:  " "
  authors: S. Gunasekar, J. Lee, **D. Soudry**, N. Srebro
  link:
    url:  https://arxiv.org/abs/1802.08246
    display:   ICML 2018
  highlight: 0
  news1: 

- title: "The Implicit Bias of Gradient Descent on Separable Data"
  image: TheImplicitBiasofGradientDescent.JPG
  description: We show that gradient descent on an unregularized logistic regression problem, for almost all separable datasets, converges to the same direction as the max-margin solution. The result generalizes also to other monotone decreasing loss functions with an infimum at infinity, and we also discuss a multi-class generalizations to the cross entropy loss. Furthermore, we show this convergence is very slow, and only logarithmic in the convergence of the loss itself.
  authors: D. Soudry, E. Hoffer, M. Shpigel Nacson, N. Srebro
  link:
    url: https://openreview.net/pdf?id=r1q7n9gAb
    display: ICLR 2018 (2018)
  highlight: 1
  news2:

- title: "Fix your classifier: the marginal value of training the last weight layer"
  image: dummy.png
  description:  " "
  authors: E. Hoffer, I. Hubara, **D. Soudry**
  link:
    url:  https://arxiv.org/abs/1801.04540
    display:   ICLR 2018
  highlight: 0
  news1: 


- title: "Train longer, generalize better: closing the generalization gap in large batch training of neural networks"
  image: dummy.png
  description:  " "
  authors: E. Hoffer * , I. Hubara * , **D. Soudry**
  link:
    url:  https://papers.nips.cc/paper_files/paper/2017/hash/a5e0ff62be0b08456fc7f1e88812af3d-Abstract.html
    display:   NIPS 2017, Oral presentation (1.2% acceptance rate)
  highlight: 0
  news1: <a href = "https://github.com/eladhoffer/bigBatch"> See more details about this paper </a> 
  
- title: "Binarized Neural Networks"
  image: BinarizedNeuralNetworksPaper.JPG
  description: We introduce a method to train Binarized Neural Networks (BNNs) - neural networks with binary weights and activations at run-time. At training-time the binary weights and activations are used for computing the parameters gradients. During the forward pass, BNNs drastically reduce memory size and accesses, and replace most arithmetic operations with bit-wise operations, which is expected to substantially improve power-efficiency. 
  authors: I. Hubara *, M. Courbariaux *, **D. Soudry**, R. El-Yaniv, Y. Bengio
  link:
    url: https://arxiv.org/abs/1602.02830
    display:  NIPS 2016 (2016)
  highlight: 1
  news1: 
  news2: 

- title: "A Fully Analog Memristor-Based Multilayer Neural Network with Online Backpropagation Training"
  image: dummy.png
  description:  " "
  authors: S. Greshnikov, E. Rosenthal, **D. Soudry**, and S. Kvatinsky
  link:
    url:  https://www.semanticscholar.org/paper/A-fully-analog-memristor-based-neural-network-with-Rosenthal-Greshnikov/66879965418dedeadadd1761b386a1dbaa67c7b2
    display:  Proceeding of the IEEE International Conference on Circuits and Systems, pp. 1394-1397, 2016
  highlight: 0
  news1: 

- title: "Expectation Backpropagation: Parameter-Free Training of Multilayer Neural Networks with Continuous Or Discrete Weights"
  image: dummy.png
  description:  " "
  authors: D. Soudry, I. Hubara and R. Meir
  link:
    url:  https://proceedings.neurips.cc/paper_files/paper/2014/file/076a0c97d09cf1a0ec3e19c7f2529f2b-Paper.pdf
    display:  NIPS 2014
  highlight: 0
  news1: <a href = "https://www.dropbox.com/s/i1aech4zd78ot3a/paper_with_appendix.pdf?dl=0"> Paper with appendix (with a few typos corrected from NIPS website) </a>  , <a href = "https://github.com/ExpectationBackpropagation/EBP_Matlab_Code/"> Code </a> ,<a href = "https://arxiv.org/abs/1503.03562"> Preliminary results on MNIST </a> 

- title: "Neuronal spike generation mechanism as an oversampling, noise-shaping A-to-D converter"
  image: dummy.png
  description:  " "
  authors:  D. B. Chklovskii and **D. Soudry**
  link:
    url:  https://papers.nips.cc/paper_files/paper/2012/hash/36660e59856b4de58a219bcf4e27eba3-Abstract.html
    display:  NIPS, 2012
  highlight: 0
  news1: 

- title: "Training of Quantized Deep Neural Networks using a Magnetic Tunnel Junction-Based Synapse"
  image: dummy.png
  description:  " "
  authors:  T. Greenberg-Toledo, B. Perach, I. Hubara, **D. Soudry**, S. Kvatinsky
  link:
    url:  https://iopscience.iop.org/article/10.1088/1361-6641/ac251b/meta
    display:  to appear in  Semiconductor Science and Technology, 2021
  highlight: 0
  news1: 


- title: "Task Agnostic Continual Learning Using Online Variational Bayes with Fixed-Point Updates" 
  image: dummy.png
  description:  " "
  authors:   C. Zeno *, I. Golan *, E. Hoffer, **D. Soudry**
  link:
    url: https://direct.mit.edu/neco/article/33/11/3139/107073/Task-Agnostic-Continual-Learning-Using-Online
    display:  Neural Computation, 2021
  highlight: 0
  news1: 

- title: "The Global Optimization Geometry of Shallow Linear Neural Networks" 
  image: dummy.png
  description:  " "
  authors:    Z. Zhu, **D. Soudry**, Y. C. Eldar, M. B. Wakin
  link:
    url: https://link.springer.com/article/10.1007/s10851-019-00889-w?wt_mc=Internal.Event.1.SEM.ArticleAuthorOnlineFirst&utm_source=ArticleAuthorContributingOnlineFirst&utm_medium=email&utm_content=AA_en_06082018&ArticleAuthorContributingOnlineFirst_20190603
    display:  Journal of Mathematical Imaging and Vision, 2019
  highlight: 0
  news1: 

- title: "Seizure pathways: A model-based investigation" 
  image: dummy.png
  description:  " "
  authors:    P. J. Karoly, L. Kuhlmann, **D. Soudry**, D. B. Grayden, M. J. Cook, D. R. Freestone
  link:
    url: https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006403
    display: PLoS Comput Biol., vol. 14 no. 10, e1006403, 2018
  highlight: 0
  news1: 

- title: "The Implicit Bias of Gradient Descent on Separable Data" 
  image: dummy.png
  description:  " "
  authors:     D. Soudry, E. Hoffer, M. Shpigel Nacson, S. Gunasekar, N. Srebro
  link:
    url: https://jmlr.org/papers/v19/18-188.html
    display: JMLR, 2018
  highlight: 0
  news1: 

- title: "Bifurcation Analysis of Two Coupled Jansen-Rit Neural Mass Models"
  image: dummy.png
  description:  " "
  authors: S. Ahmadizadeh, P. Jane Karoly, D. Nesic, D. Br. Grayden, M. J.Cook, **D. Soudry**, D. R. Freestone
  link:
    url: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0192842
    display: PLOS One, vol. 13 no. 3, e0192842, 2018
  news1: 

- title: "Quantized Neural Networks: Training Neural Networks with Low Precision Weights and Activations"
  image: dummy.png
  description:  " "
  authors:  I. Hubara * , M. Courbariaux * ,**D. Soudry**, R. El-Yaniv, Y. Bengio. 
  link:
    url: https://jmlr.org/papers/v18/16-456.html
    display: JMLR, 2018
  news1: 

- title: "Multi-scale approaches for high-speed imaging and analysis of large neural populations"
  image: dummy.png
  description:  " "
  authors:   J. Friedrich, W. Yang, **D. Soudry**, Y. Mu, M. B. Ahrens, R. Yuste, D. S. Peterka, L. Paninski 
  link:
    url: https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005685
    display: PLos Comput Biol, vol., 13 no. 8, e1005685, 2017
  news1: 

- title: "Extracting grid cell characteristics from place cell inputs using non-negative principal component analysis"
  image: dummy.png
  description:  " "
  authors:    Y. Dordek *, D. Soudry *, R. Meir, D. Derdikman
  link:
    url: https://elifesciences.org/articles/10094v2
    display: eLife, vol. 5, e10094, 2016
  news1: <a href="https://elifesciences.org/articles/10094v2"> F1000 Recommended </a>

- title: "Simultaneous Denoising, Deconvolution, and Demixing of Calcium Imaging Data"
  image: dummy.png
  description:  " "
  authors:  E. A. Pnevmatikakis, **D. Soudry**, Y. Gao, T. A. Machado, J. Merel, D. Pfau,T. Reardon,Y. Mu, C. Lacefield, W. Yang, M. Ahrens, R. Bruno, T. M. Jessell, D. S. Peterka, R. Yuste, L. Paninski,
  link:
    url: https://www.cell.com/neuron/fulltext/S0896-6273(15)01084-3
    display: Neuron, vol. 89, no. 2,  2016
  news1: <a href="https://www.cell.com/cms/attachment/2046949148/2057837139/mmc1.pdf"> ِAppendix </a> , <a href="https://github.com/flatironinstitute/CaImAn-MATLAB">Code </a>

- title: "Efficient 'Shotgun' Inference of Neural Connectivity from Highly Sub-sampled Activity Data"
  image: dummy.png
  description:  " "
  authors:   D. Soudry, S. Keshri, P. Stinson, M.H. Oh, G. Iyengar, L. Paninski
  link:
    url: https://journals.plos.org/ploscompbiol/article?id=10.1371%2Fjournal.pcbi.1004464
    display:  PLoS Comput Biol, vol. 11, no. 10, 2015
  news1: <a href="https://videolectures.net/netadis2015_soudry_activity_data/"> 5 mins presentation </a> , <a href="https://github.com/danielso/Shotgun">Code </a>

- title: "Memristor-based multilayer neural networks with online gradient descent training"
  image: dummy.png
  description:  " "
  authors: D. Soudry, D. Di Castro, A. Gal, A. Kolodny, and S. Kvatinsky
  link:
    url: https://ieeexplore.ieee.org/document/7010034
    display:  IEEE TNNLS, vol. 26, no. 10, 2015
  news1: <a href="https://www.dropbox.com/sh/7je4fufb6d4c2sr/AAA7RgsIlsRu-lNN6imELqjDa?dl=0"> Complete Code </a> 

- title: "Diffusion approximation-based simulation of stochastic ion channels: which method to use?"
  image: dummy.png
  description:  " "
  authors: D. Pezo, **D. Soudry**, P. Orio
  link:
    url: https://www.frontiersin.org/articles/10.3389/fncom.2014.00139/full
    display:  Front. Comput. Neurosci., vol. 8, no. 139, 2014
  news1: 
    
- title: "The neuronal response at extended timescales: a linearized spiking input-output relation"
  image: dummy.png
  description:  " "
  authors:  D. Soudry and R. Meir
  link:
    url: https://www.frontiersin.org/articles/10.3389/fncom.2014.00029/full
    display:  Front. Comput. Neurosci., vol. 8, no. 29, 2014
  news1: 
       
- title: "The neuronal response at extended timescales: long term correlations without long memory"
  image: dummy.png
  description:  " "
  authors:  D. Soudry and R. Meir
  link:
    url: https://www.frontiersin.org/articles/10.3389/fncom.2014.00029/full
    display:  Front. Comput. Neurosci., vol. 8, no. 35, 2014
  news1:

- title: "Simple, fast and accurate implementation of the diffusion approximation algorithm for stochastic ion channels with multiple states"
  image: dummy.png
  description:  " "
  authors: P. Orio and **D. Soudry**
  link:
    url: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0036670
    display: PLoS ONE, vol. 7, no. 5 p. e36670, 2012
  news1:


- title: "Conductance-based neuron models and the slow dynamics of excitability"
  image: dummy.png
  description:  " "
  authors: D. Soudry and R. Meir
  link:
    url: https://www.frontiersin.org/articles/10.3389/fncom.2012.00004/full
    display: Front. Comput. Neurosci., vol. 6, no. 4, 2012
  news1:
 
- title: "History-Dependent Dynamics in a Generic Model of Ion Channels–An Analytic Study"
  image: dummy.png
  description:  " "
  authors: D. Soudry and R. Meir
  link:
    url: https://www.frontiersin.org/articles/10.3389/fncom.2010.00003/full
    display: Front. Comput. Neurosci., vol. 4, Jan. 2010
  news1:

- title: "Why Cold Posteriors? On the Suboptimal Generalization of Optimal Bayes Estimates"
  image: dummy.png
  description:  " "
  authors: C. Zeno, I. Golan, A. Pakman, **D. Soudry**
  link:
    url: https://openreview.net/forum?id=cu6zDHCfhZx
    display: Third Symposium on Advances in Approximate Bayesian Inference, contributed talk (2021).
  news1:

- title: "How Learning Rate and Delay Affect Minima Selection in Asynchronous Training of Neural Networks: Toward Closing the Generalization Gap (Oral)"
  image: dummy.png
  description:  " "
  authors: N. Giladi * , Mor Shpigel * , E. Hoffer, **D. Soudry**
  link:
    url: https://drive.google.com/file/d/101yxxakquNQYtr5CD7bdbDgDLVmt1H-J/view
    display: ICML 'Understanding and Improving Generalization in Deep Learning' workshop (2019)
  news1:  
 
- title: "A Mean Field Theory of Quantized Deep Networks: The Quantization-Depth Trade-Off (Oral)"
  image: dummy.png
  description:  " "
  authors:  Y. Blumenfeld, D. Gilboa, **D. Soudry**
  link:
    url: https://arxiv.org/abs/1906.00771
    display:  ICML 'Physics for deep learning' workshop (2019)
  news1: 

- title: "Increasing batch size through instance repetition improves generalization (Poster)"
  image: dummy.png
  description:  " "
  authors:  E. Hoffer, T. Ben-Nun, N. Giladi, I. Hubara, T. Hoefler, **D. Soudry**
  link:
    url: https://arxiv.org/abs/1901.09335
    display: ICML 'Understanding and Improving Generalization in Deep Learning' workshop, poster (2019)
  news1:  

- title: "Task Agnostic Continual Learning Using Online Variational Bayes (Poster)"
  image: dummy.png
  description:  " "
  authors:  C. Zeno *, I. Golan *, E. Hoffer, **D. Soudry**
  link:
    url: https://arxiv.org/abs/1803.10123
    display:  NIPS Deep Bayesian learning workshop, 2018
  news1:  

- title: "Infer2Train: leveraging inference for better training of deep networks (Poster)"
  image: dummy.png
  description:  " "
  authors:   E Hoffer, B Weinstein, I Hubara, S Gofman, **D Soudry**
  link:
    url: http://learningsys.org/nips18/assets/papers/24CameraReadySubmissionInfer2Train.pdf
    display: NIPS Deep Bayesian learning workshop, 2018
  news1:  

- title: "Exponentially vanishing sub-optimal local minima in multilayer neural networks (Poster)"
  image: dummy.png
  description:  " "
  authors:  D. Soudry, E. Hoffer
  link:
    url: https://arxiv.org/abs/1702.05777
    display: ICLR workshop, 2018
  news1:  

- title: "Quantized Neural Networks (Poster)"
  image: dummy.png
  description:  " "
  authors: I. Hubara * , M. Courbariaux  *, **D. Soudry**, R. El-Yaniv, Y. Bengio
  link:
    url: 
    display: NIPS workshop on Efficient Methods for Deep Neural Networks  (2016)
  news1:  


- title: "Quantized Neural Networks (Poster)"
  image: dummy.png
  description:  " "
  authors: I. Hubara * , M. Courbariaux  *, **D. Soudry**, R. El-Yaniv, Y. Bengio
  link:
    url: 
    display: NIPS workshop on Efficient Methods for Deep Neural Networks  (2016)
  news1:  


- title: "Binarized neural networks (Poster)"
  image: dummy.png
  description:  " "
  authors: I. Hubara * , M. Courbariaux  *, **D. Soudry**, R. El-Yaniv, Y. Bengio
  link:
    url: 
    display: Machine Learning seminar, IBM research center, Haifa (2016)
  news1:  

- title: "Data-driven neural models part II: connectivity patterns of human seizures (Best student poster)"
  image: dummy.png
  description:  " "
  authors: P. J. Karoly, D. R. Freestone, **D. Soudry**, L. Kuhlmann, L. Paninski, M. Cook
  link:
    url: 
    display: CNS (2016)
  news1:  

- title: "Data-driven neural models part I: state and parameter estimation (Poster)"
  image: dummy.png
  description:  " "
  authors: D. R. Freestone, P. J. Karoly, **D. Soudry**, L. Kuhlmann, M.Cook
  link:
    url: 
    display: CNS (2016)
  news1:  


- title: "Extracting grid characteristics from spatially distributed place cell inputs using non-negative PCA (Poster)"
  image: dummy.png
  description:  " "
  authors: Y. Dordek * ,  D. Soudry * , R. Meir,  D. Derdikman
  link:
    url: 
    display: SFN (2015)
  news1:  

- title: "Fast Constrained Non-negative Matrix Factorization for Whole-Brain Calcium Imaging Data (Poster)"
  image: dummy.png
  description:  " "
  authors: J. Friedrich, **D. Soudry**, Y. Mu, J. Freeman, M. Ahrens, and L. Paninski
  link:
    url: https://users.soe.ucsc.edu/~afletcher/neuralsysnips.html
    display: NIPS workshop on Statistical Methods for Understanding Neural Systems (2015)
  news1:  

- title: "Implementing efficient 'shotgun' inference of neural connectivity from highly sub-sampled activity data (Spotlight Presentation and poster)"
  image: dummy.png
  description:  " "
  authors:  D. Soudry, S. Keshri, P. Stinson, M.H. Oh, G. Iyengar, L. Paninski
  link:
    url: https://videolectures.net/netadis2015_soudry_activity_data/
    display: NIPS workshop on Modelling and Inference for Dynamics on Complex Interaction Networks (2015)
  news1:  


- title: "Expectation Backpropagation: Parameter-Free Training of Multilayer Neural Networks with Continuous Or Discrete Weights (Poster)"
  image: dummy.png
  description:  " "
  authors:  D. Soudry,I. Hubara and R. Meir
  link:
    url: 
    display: Machine Learning seminar (IBM research center, Haifa 2015)
  news1:  


- title: Efficient “shotgun” inference of neural connectivity from highly sub-sampled activity data (Oral)"
  image: dummy.png
  description:  " "
  authors:  D. Soudry, S. Keshri, P. Stinson, M.H. Oh, G. Iyengar, L. Paninski
  link:
    url: 
    display:  Swartz Annual Meeting at Janelia Research Campus (2015)
  news1:  

- title: "A shotgun sampling solution for the common input problem in neural connectivity inference (Poster)"
  image: dummy.png
  description:  " "
  authors:  D. Soudry, S. Keshri, P. Stinson, M.H. Oh, G. Iyengar, L. Paninski
  link:
    url: 
    display:  COSYNE (2015)
  news1:  

- title: " Whole Brain Region of Interest Detection (Poster)"
  image: dummy.png
  description:  " "
  authors:  D. Pfau *, D. Soudry *, Y. Gao, Y. Mu, J. Freeman, M. Ahrens, L. Paninski 
  link:
    url: 
    display:  NIPS workshop on Large scale optical physiology: From data-acquisition to models of neural coding (2014)
  news1:  

- title: " Whole Brain Region of Interest Detection (Poster)"
  image: dummy.png
  description:  " "
  authors:  D. Pfau *, D. Soudry *, Y. Gao, Y. Mu, J. Freeman, M. Ahrens, L. Paninski 
  link:
    url: 
    display:  AREADNE (2014)
  news1:  

- title: " Mean Field Bayes Backpropagation: scalable training of multilayer neural networks with discrete weights (Poster)"
  image: dummy.png
  description:  " "
  authors:  D. Soudry and R. Meir
  link:
    url: 
    display:  Machine Learning seminar (IBM research center, Haifa 2013)
  news1:  


- title: "Implementing Hebbian Learning Rules with Memristors (Poster)"
  image: dummy.png
  description:  " "
  authors:  D. Soudry, D. Di Castro, A. Gal, A. Kolodny, and S. Kvatinsky
  link:
    url: 
    display: Memristor-based Systems for Neuromorphic Applications (Torino University 2013)
  news1:  

- title: "A spiking input-output relation for general biophysical neuron models explains observed 1/f response (Poster)"
  image: dummy.png
  description:  " "
  authors:  D. Soudry and R. Meir
  link:
    url: 
    display:  COSYNE (2013)
  news1:  


- title: "Spiking input-output relation of general biophysical neuron models – exact analytic solutions and comparisons with experiment (Poster)"
  image: dummy.png
  description:  " "
  authors:  D. Soudry and R. Meir
  link:
    url: 
    display:  Variants and invariants in brain and behavior (Technion 2012)
  news1:  


- title: "The slow dynamics of neuronal excitability - exact analytic solutions for the response of general biophysical neuron models at long times, and comparisons with experiment (Poster)"
  image: dummy.png
  description:  " "
  authors:  D. Soudry and R. Meir
  link:
    url: 
    display:  Brain Plasticity Symposium (Tel Aviv university 2012)
  news1:  

- title: "The slow dynamics of neuronal excitability (Poster)"
  image: dummy.png
  description:  " "
  authors:  D. Soudry and R. Meir
  link:
    url: 
    display:  ISFN (2012)
  news1:  

- title: "The neuron as a population of ion channels: The emergence of stochastic and history dependent behavior (Poster)"
  image: dummy.png
  description:  " "
  authors:  D. Soudry and R. Meir
  link:
    url: 
    display:  COSYNE (2011)
  news1:  

- title: "The neuron as a population of ion channels: The emergence of stochastic and history dependent behavior (Oral)"
  image: dummy.png
  description:  " "
  authors:  D. Soudry and R. Meir
  link:
    url: 
    display:  ISFN (2010)
  news1:  

  
- title: "History dependent dynamics in ion channels - an analytic study (Poster)"
  image: dummy.png
  description:  " "
  authors:  D. Soudry and R. Meir
  link:
    url: 
    display:  COSYNE (2010)
  news1:  

- title: "Adapting Timescales: From Channel to Neuron” (Oral)"
  image: dummy.png
  description:  " "
  authors:  D. Soudry and R. Meir
  link:
    url: 
    display:  ISFN (2009)
  news1:  

- title: "Mix & Match: training convnets with mixed image sizes for improved accuracy, speed and scale resiliency"
  image: dummy.png
  description:  " "
  authors:  E. Hoffer, B. Weinstein, I. Hubara, T. Ben-Nun, T. Hoefler, **D. Soudry**
  link:
    url: https://arxiv.org/abs/1908.08986
    display:  See Here
  news1:  

- title: "On the Blindspots of Convolutional Networks"
  image: dummy.png
  description:  " "
  authors:   E. Hoffer, S. Fine, **D. Soudry**
  link:
    url: https://arxiv.org/abs/1802.05187
    display:  See Here
  news1:  

  - title: "No bad local minima: Data independent training error guarantees for multilayer neural networks"
  image: dummy.png
  description:  " "
  authors:   D. Soudry, E. Hoffer
  link:
    url: https://arxiv.org/abs/1605.08361
    display:  See Here
  news1:  
